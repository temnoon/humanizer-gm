/**
 * AUI Context - Central hub for the Agentic UI system
 *
 * Combines:
 * - Chat interface (messages, LLM communication)
 * - Tool execution with teaching
 * - Animation orchestration ("show don't tell")
 * - Settings persistence
 * - Chat archiving (conversations become searchable content)
 *
 * Philosophy:
 * Every AUI interaction is archived and becomes part of the user's corpus.
 * The AUI teaches by doing - animations show how to replicate actions manually.
 */

import {
  createContext,
  useContext,
  useCallback,
  useState,
  useEffect,
  useRef,
  useMemo,
  type ReactNode,
} from 'react';

import { auiAnimator, teachingToAnimation, type AnimatorState } from './animator';
import { loadAUISettings, saveAUISettings, type AUISettings } from './settings';
import { executeAllTools, cleanToolsFromResponse, AUI_BOOK_SYSTEM_PROMPT, type AUIContext as AUIToolContext, type AUIToolResult } from './tools';
import { useLayout } from '../../components/layout/LayoutContext';
import { useBookshelf } from '../bookshelf';
import { useBookStudioOptional } from '../book-studio';
import { getArchiveServerUrl } from '../platform';
import {
  getAgentBridge,
  type AgentProposal,
  type AgentInfo,
  type BridgeEvent,
} from './agent-bridge';

// ═══════════════════════════════════════════════════════════════════
// TYPES
// ═══════════════════════════════════════════════════════════════════

export interface ChatMessage {
  id: string;
  role: 'user' | 'assistant' | 'system' | 'tool';
  content: string;
  timestamp: Date;
  /** Tool results if this is a tool message */
  toolResults?: AUIToolResult[];
  /** Whether this message has been archived */
  archived?: boolean;
  /** Whether this message was generated by a cloud LLM (data left local machine) */
  isCloud?: boolean;
  /** Which model generated this message */
  model?: string;
  /** Which provider was used */
  provider?: string;
}

export interface AUIConversation {
  id: string;
  messages: ChatMessage[];
  startedAt: Date;
  title?: string;
  tags: string[];
}

export interface AUIState {
  /** Current conversation */
  conversation: AUIConversation;
  /** Whether LLM is processing */
  isLoading: boolean;
  /** Current error if any */
  error: string | null;
  /** Animation state */
  animation: AnimatorState;
  /** Settings */
  settings: AUISettings;
  /** Whether chat panel is open */
  isChatOpen: boolean;
  /** Pending agent proposals */
  pendingProposals: AgentProposal[];
  /** Available agents */
  agents: AgentInfo[];
  /** Whether agent orchestrator is connected */
  agentBridgeConnected: boolean;
}

export interface AUIContextValue {
  state: AUIState;
  /** Send a message to AUI */
  sendMessage: (content: string) => Promise<void>;
  /** Clear current conversation */
  clearConversation: () => void;
  /** Archive current conversation */
  archiveConversation: () => Promise<void>;
  /** Toggle chat visibility */
  toggleChat: () => void;
  /** Open chat */
  openChat: () => void;
  /** Close chat */
  closeChat: () => void;
  /** Update settings */
  updateSettings: <K extends keyof AUISettings>(
    category: K,
    updates: Partial<AUISettings[K]>
  ) => void;
  /** Stop current animation */
  stopAnimation: () => void;
  /** Approve an agent proposal */
  approveProposal: (proposalId: string) => Promise<AUIToolResult | null>;
  /** Reject an agent proposal */
  rejectProposal: (proposalId: string, reason?: string) => void;
  /** Request work from an agent */
  requestAgentWork: (
    agentId: string,
    taskType: string,
    payload: unknown,
    projectId?: string
  ) => Promise<{ taskId: string } | { error: string }>;
  /** Update workspace state (called by StudioContent) */
  setWorkspace: (workspace: AUIToolContext['workspace']) => void;
}

// ═══════════════════════════════════════════════════════════════════
// ELECTRON CHAT API TYPE
// ═══════════════════════════════════════════════════════════════════

interface ElectronChatMessage {
  id: string;
  role: 'user' | 'assistant' | 'system' | 'tool';
  content: string;
  timestamp: number;
  /** Whether this was a cloud LLM call */
  isCloud?: boolean;
  /** Model used */
  model?: string;
  /** Provider used */
  provider?: string;
}

interface ElectronChatAPI {
  chat: {
    sendMessage: (content: string, options?: { context?: string }) => Promise<ElectronChatMessage[]>;
    getMessages: (conversationId?: string) => Promise<ElectronChatMessage[]>;
    startConversation: () => Promise<{ id: string }>;
  };
}

// ═══════════════════════════════════════════════════════════════════
// WORKSPACE CONTEXT BUILDER
// ═══════════════════════════════════════════════════════════════════

import type { BookStudioContextValue } from '../book-studio/BookStudioProvider';

/**
 * Build a context string from current workspace state
 * This is passed to the LLM so it knows what the user is looking at
 *
 * Includes:
 * - Book Studio state (all books, active book, chapters, cards, voices)
 * - Current workspace selection
 * - View mode
 */
function buildWorkspaceContext(
  workspace: AUIToolContext['workspace'] | undefined,
  book: { activeProject: { id: string } | null } | null,
  bookStudio: BookStudioContextValue | null
): string {
  const parts: string[] = [];

  // ═══════════════════════════════════════════════════════════════════
  // 1. BOOK STUDIO STATE (Primary context for book-building)
  // ═══════════════════════════════════════════════════════════════════

  if (bookStudio) {
    const { books, activeBook, activeBookId, voice } = bookStudio;

    // List all books
    if (books.length > 0) {
      parts.push(`## Your Books (${books.length} total)`);
      books.forEach((b, i) => {
        const isActive = b.id === activeBookId;
        const marker = isActive ? ' [ACTIVE]' : '';
        const cardCount = b.cardCount ?? b.stagingCards?.length ?? 0;
        const chapterCount = b.chapterCount ?? b.chapters?.length ?? 0;
        parts.push(`${i + 1}. "${b.title}"${marker} - ${cardCount} cards, ${chapterCount} chapters`);
      });
      parts.push('');
    } else {
      parts.push('## Your Books: No books yet. Use create_book to start.\n');
    }

    // Active book details
    if (activeBook) {
      parts.push(`## Active Book: "${activeBook.title}"`);
      if (activeBook.description) {
        parts.push(`Description: ${activeBook.description}`);
      }

      // Chapters with details
      if (activeBook.chapters.length > 0) {
        parts.push(`\n### Chapters (${activeBook.chapters.length}):`);
        activeBook.chapters.forEach((ch, i) => {
          const cardCount = ch.cards?.length || 0;
          const wordStr = ch.wordCount > 0 ? `${ch.wordCount} words` : 'empty';
          parts.push(`  ${i + 1}. "${ch.title}" (${wordStr}, ${cardCount} cards)`);
        });
      } else {
        parts.push('\n### Chapters: None yet. User can create with create_chapter or generate_outline.');
      }

      // Staging cards summary
      const stagingCards = activeBook.stagingCards || [];
      const stagingCount = stagingCards.filter(c => c.status === 'staging').length;
      const placedCount = stagingCards.filter(c => c.status === 'placed').length;

      parts.push(`\n### Cards:`);
      parts.push(`  - Staging (unassigned): ${stagingCount}`);
      parts.push(`  - Placed in chapters: ${placedCount}`);
      parts.push(`  - Total: ${stagingCards.length}`);

      // Voice profiles
      const voices = voice?.state?.voices || [];
      if (voices.length > 0) {
        parts.push(`\n### Voice Profiles:`);
        voices.forEach(v => {
          const primary = v.isPrimary ? ' [PRIMARY]' : '';
          parts.push(`  - "${v.name}"${primary}`);
        });
      }

      // Agent states
      const { harvest, outline, draft } = bookStudio;
      if (harvest.state.isRunning) {
        parts.push(`\n### Agents: Harvest in progress...`);
      }
      if (outline.state.isGenerating || outline.state.isResearching) {
        parts.push(`\n### Agents: Outline generation in progress...`);
      }
      if (draft.state.isGenerating) {
        parts.push(`\n### Agents: Draft generation for "${draft.state.progress?.chapterTitle || 'chapter'}"...`);
      }

      parts.push('');
    }
  }

  // ═══════════════════════════════════════════════════════════════════
  // 2. CURRENT WORKSPACE SELECTION
  // ═══════════════════════════════════════════════════════════════════

  // Currently selected container (unified content model)
  if (workspace?.selectedContainer) {
    const container = workspace.selectedContainer;
    const title = container.meta?.title || container.id;
    const contentPreview = container.content?.raw?.slice(0, 300) || '';

    parts.push(`## Current Selection`);
    parts.push(`Type: ${container.type}`);
    parts.push(`Title: "${title}"`);

    // Add source info
    if (container.source?.type) {
      parts.push(`Source: ${container.source.type}${container.source.originalId ? ` (${container.source.originalId})` : ''}`);
    }

    // Add content preview
    if (contentPreview) {
      parts.push(`Preview: "${contentPreview}${container.content?.raw && container.content.raw.length > 300 ? '...' : ''}"`);
    }

    // Add metadata
    if (container.meta?.tags?.length) {
      parts.push(`Tags: ${container.meta.tags.join(', ')}`);
    }
    parts.push('');
  }

  // Active buffer content (if different from container)
  if (workspace?.bufferContent && !workspace?.selectedContainer) {
    const preview = workspace.bufferContent.slice(0, 500);
    parts.push(`## Current Buffer`);
    parts.push(`Name: "${workspace.bufferName || 'untitled'}"`);
    parts.push(`Length: ${workspace.bufferContent.length} chars`);
    parts.push(`Preview: "${preview}${workspace.bufferContent.length > 500 ? '...' : ''}"`);
    parts.push('');
  }

  // Current view mode
  if (workspace?.viewMode) {
    parts.push(`## View Mode: ${workspace.viewMode}`);
  }

  // Legacy: Selected Facebook content (fallback if no container)
  if (workspace?.selectedContent && !workspace?.selectedContainer) {
    parts.push(`## Legacy Selection`);
    parts.push(`Viewing: ${workspace.selectedContent.type} from ${workspace.selectedContent.source || 'unknown'}`);
  }

  // Active book info (legacy from bookshelf)
  if (book?.activeProject && !bookStudio?.activeBook) {
    const project = book.activeProject;
    parts.push(`## Legacy Book: ${project.id}`);
  }

  return parts.length > 0 ? parts.join('\n') : 'No workspace context available.';
}

// ═══════════════════════════════════════════════════════════════════
// SYSTEM PROMPT
// ═══════════════════════════════════════════════════════════════════

// Build full system prompt with intro and context-awareness instructions
const AUI_SYSTEM_PROMPT_INTRO = `You are AUI (Agentic User Interface), an assistant integrated into the Humanizer Studio.

## CRITICAL: You Know the Workspace State

Your context includes the current state of the user's workspace:
- All books they have (with card counts, chapter counts)
- The active book (with detailed chapter list, card status, voice profiles)
- What content is currently selected or displayed
- What view mode they're using

**ALWAYS use this context to answer questions about the GUI state.** When the user asks "What books do I have?" or "How many cards are in staging?" - you KNOW this from the context above.

## IMPORTANT RULES

1. **When asked about GUI state, answer directly from context** - don't use tools to "look up" what you already know.
2. **When asked to take actions, use USE_TOOL** to execute them. Don't describe what you would do - actually do it.
3. **Be concise.** Don't explain what you're about to do unless the user asked for explanation.
4. **Use natural vocabulary mapping:**
   - "this book" / "my book" / "the current book" → the active book
   - "this chapter" / "the current chapter" → depends on context
   - "staging cards" / "unassigned cards" → cards with status "staging"
   - "add this to the book" → harvest_card
   - "move to chapter X" → move_card

`;

// Full system prompt combines intro + comprehensive tool documentation
const AUI_SYSTEM_PROMPT = AUI_SYSTEM_PROMPT_INTRO + AUI_BOOK_SYSTEM_PROMPT;

// ═══════════════════════════════════════════════════════════════════
// CONTEXT
// ═══════════════════════════════════════════════════════════════════

const AUIContext = createContext<AUIContextValue | null>(null);

export function useAUI(): AUIContextValue {
  const context = useContext(AUIContext);
  if (!context) {
    throw new Error('useAUI must be used within an AUIProvider');
  }
  return context;
}

// ═══════════════════════════════════════════════════════════════════
// PROVIDER
// ═══════════════════════════════════════════════════════════════════

interface AUIProviderProps {
  children: ReactNode;
  /** Workspace state for tool context */
  workspace?: AUIToolContext['workspace'];
}

export function AUIProvider({ children, workspace: initialWorkspace }: AUIProviderProps) {
  // Dependencies
  const layout = useLayout();
  const bookshelf = useBookshelf();
  const bookStudio = useBookStudioOptional(); // Book Studio context for enhanced GUI awareness

  // Build book interface from bookshelf's simple methods
  // IMPORTANT: Memoize to prevent infinite re-renders in useEffect dependencies
  const book = useMemo(() => ({
    // Use both names for compatibility with different tool versions
    activeProject: bookshelf.activeBook || null,
    activeBook: bookshelf.activeBook || null,

    createProject: (name: string, subtitle?: string) => {
      const id = `book-${Date.now()}`;
      const uri = `book://user/${name.toLowerCase().replace(/\s+/g, '-')}`;
      console.log('[AUI] Creating book via bookshelf.createBook:', name, subtitle);

      // Fire and forget - actual creation is async
      void (async () => {
        const newBook = await bookshelf.createBook({
          id,
          name,
          subtitle,
          status: 'harvesting',
          createdAt: Date.now(),
          updatedAt: Date.now(),
          personaRefs: [],
          styleRefs: [],
          threads: [],
          sourceRefs: [],
          passages: [],
          chapters: [],
          tags: [],
          stats: { totalSources: 0, totalPassages: 0, approvedPassages: 0, gems: 0, chapters: 0, wordCount: 0 },
        });
        if (newBook?.uri) {
          bookshelf.setActiveBookUri(newBook.uri);
        }
      })();

      // Return placeholder for sync interface
      return {
        id,
        uri,
        type: 'book' as const,
        name,
        subtitle,
        status: 'harvesting' as const,
        createdAt: Date.now(),
        updatedAt: Date.now(),
        personaRefs: [],
        styleRefs: [],
        threads: [],
        sourceRefs: [],
        passages: [],
        chapters: [],
        tags: [],
        stats: { totalSources: 0, totalPassages: 0, approvedPassages: 0, gems: 0, chapters: 0, wordCount: 0 },
      };
    },

    updateChapter: (chapterId: string, content: string, changes?: string) => {
      void bookshelf.updateChapterSimple(chapterId, content, changes);
    },

    createChapter: (title: string, content?: string) => {
      void bookshelf.createChapterSimple(title, content);
      // Return placeholder for sync interface - actual chapter created async
      return {
        id: `ch-${Date.now()}`,
        number: 1,
        title,
        content: content || `# ${title}\n\n`,
        wordCount: 0,
        version: 1,
        versions: [],
        status: 'outline' as const,
        sections: [],
        marginalia: [],
        metadata: { lastEditedBy: 'aui' as const, lastEditedAt: Date.now(), notes: [], auiSuggestions: [] },
        passageRefs: [],
      };
    },

    deleteChapter: (chapterId: string) => {
      void bookshelf.deleteChapterSimple(chapterId);
    },

    renderBook: () => bookshelf.renderActiveBook() || '',

    getChapter: (chapterId: string) => bookshelf.getChapterSimple(chapterId) || null,

    addPassage: (passage: {
      content: string;
      conversationId?: string;
      conversationTitle: string;
      role?: 'user' | 'assistant';
      tags?: string[];
    }) => {
      void bookshelf.addPassageSimple(passage);
      // Return placeholder - actual passage created async
      return {
        id: `p-${Date.now()}`,
        text: passage.content,
        wordCount: passage.content.split(/\s+/).length,
      } as import('../bookshelf/types').SourcePassage;
    },

    updatePassage: (passageId: string, updates: Partial<import('../bookshelf/types').SourcePassage>) => {
      void bookshelf.updatePassageSimple(passageId, updates);
    },

    getPassages: () => bookshelf.getPassagesSimple() || [],
  }), [
    bookshelf.activeBook,
    bookshelf.createBook,
    bookshelf.setActiveBookUri,
    bookshelf.updateChapterSimple,
    bookshelf.createChapterSimple,
    bookshelf.deleteChapterSimple,
    bookshelf.renderActiveBook,
    bookshelf.getChapterSimple,
    bookshelf.addPassageSimple,
    bookshelf.updatePassageSimple,
    bookshelf.getPassagesSimple,
  ]);

  // State - settings must be loaded first since createNewConversation uses it
  const [settings, setSettings] = useState<AUISettings>(loadAUISettings);
  const [conversation, setConversation] = useState<AUIConversation>(() =>
    createNewConversation(settings)
  );
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [animationState, setAnimationState] = useState<AnimatorState>(
    auiAnimator.getState()
  );
  const [isChatOpen, setIsChatOpen] = useState(false);
  const [pendingProposals, setPendingProposals] = useState<AgentProposal[]>([]);
  const [agents, setAgents] = useState<AgentInfo[]>([]);
  const [agentBridgeConnected, setAgentBridgeConnected] = useState(false);

  // Workspace state - can be set from StudioContent
  const [workspaceState, setWorkspaceState] = useState<AUIToolContext['workspace']>(initialWorkspace);

  // Refs
  const abortControllerRef = useRef<AbortController | null>(null);
  const bridgeRef = useRef(getAgentBridge());

  // Initialize animator with layout context
  useEffect(() => {
    auiAnimator.setLayoutContext(layout);
    auiAnimator.setStateChangeCallback(setAnimationState);
  }, [layout]);

  // Initialize agent bridge and subscribe to events
  useEffect(() => {
    const bridge = bridgeRef.current;

    // Build tool context for the bridge
    const toolContext: AUIToolContext = {
      activeProject: book.activeProject,
      createProject: book.createProject,
      updateChapter: book.updateChapter,
      createChapter: book.createChapter,
      deleteChapter: book.deleteChapter,
      renderBook: book.renderBook,
      getChapter: book.getChapter,
      addPassage: book.addPassage,
      updatePassage: book.updatePassage,
      getPassages: book.getPassages,
      workspace: workspaceState,
    };

    // Initialize bridge with context
    bridge.initialize(toolContext);
    bridge.updateConfig(settings);

    // Update state from bridge
    setPendingProposals(bridge.getPendingProposals());
    setAgents(bridge.getAgents());
    setAgentBridgeConnected(bridge.isConnected());

    // Subscribe to bridge events
    const unsubscribe = bridge.onEvent((event: BridgeEvent) => {
      switch (event.type) {
        case 'proposal:received': {
          setPendingProposals(bridge.getPendingProposals());
          // Add proposal to chat if showProposals is enabled
          if (settings.automation.showProposals) {
            const formatted = bridge.formatProposalForChat(event.proposal);
            const proposalMessage: ChatMessage = {
              id: `proposal-${event.proposal.id}`,
              role: 'system',
              content: formatted,
              timestamp: new Date(),
            };
            setConversation((prev) => ({
              ...prev,
              messages: [...prev.messages, proposalMessage],
            }));
          }
          break;
        }
        case 'proposal:expired':
          setPendingProposals(bridge.getPendingProposals());
          break;
        case 'tool:completed': {
          // Add tool result to chat
          const resultMessage: ChatMessage = {
            id: `agent-tool-${event.requestId}`,
            role: 'tool',
            content: event.result.success
              ? `✓ ${event.result.message || 'Completed'}`
              : `✗ ${event.result.error || 'Failed'}`,
            timestamp: new Date(),
            toolResults: [event.result],
          };
          setConversation((prev) => ({
            ...prev,
            messages: [...prev.messages, resultMessage],
          }));
          break;
        }
        case 'agent:status':
          setAgents(bridge.getAgents());
          break;
      }
    });

    return () => {
      unsubscribe();
    };
  }, [book, workspaceState, settings]);

  // Create a new conversation
  function createNewConversation(currentSettings: AUISettings): AUIConversation {
    return {
      id: `aui-${Date.now()}-${Math.random().toString(36).slice(2, 8)}`,
      messages: [
        {
          id: 'welcome',
          role: 'assistant',
          content:
            "Hi! I'm AUI, your Studio assistant. I can help you navigate, search your archives, and build your book. What would you like to do?",
          timestamp: new Date(),
        },
      ],
      startedAt: new Date(),
      tags: [currentSettings.archive.chatTag],
    };
  }

  // Send a message
  const sendMessage = useCallback(
    async (content: string) => {
      if (!content.trim() || isLoading) return;

      // Add user message
      const userMessage: ChatMessage = {
        id: `user-${Date.now()}`,
        role: 'user',
        content: content.trim(),
        timestamp: new Date(),
      };

      setConversation((prev) => ({
        ...prev,
        messages: [...prev.messages, userMessage],
      }));

      setIsLoading(true);
      setError(null);

      abortControllerRef.current = new AbortController();

      try {
        let assistantContent: string;
        let isCloud = false;
        let modelUsed: string | undefined;
        let providerUsed: string | undefined;

        // Build workspace context for the LLM (includes book studio state)
        const workspaceContext = buildWorkspaceContext(workspaceState, book, bookStudio);

        // Use Electron chat service if available (routes through AgentMaster)
        // This provides tiered prompts based on device RAM and automatic output vetting
        const electronAPI = (window as unknown as { electronAPI?: ElectronChatAPI }).electronAPI;
        const isElectron = (window as unknown as { isElectron?: boolean }).isElectron;

        if (isElectron && electronAPI?.chat) {
          // Route through AgentMaster for tiered prompts + vetting
          // sendMessage returns the new messages (including assistant response)
          const newMessages = await electronAPI.chat.sendMessage(content.trim(), {
            context: workspaceContext,
          });

          // Find the assistant's response from the returned messages
          const lastAssistant = newMessages
            .filter((m) => m.role === 'assistant')
            .pop();

          // Also check for system error messages (backend sends errors as system messages)
          const lastSystem = newMessages
            .filter((m) => m.role === 'system' && m.content.startsWith('Error:'))
            .pop();

          if (lastAssistant?.content) {
            assistantContent = lastAssistant.content;
            isCloud = lastAssistant.isCloud || false;
            modelUsed = lastAssistant.model;
            providerUsed = lastAssistant.provider;
          } else if (lastSystem?.content) {
            // Show the error to the user instead of generic message
            assistantContent = lastSystem.content;
          } else {
            assistantContent = "I couldn't process that. Make sure Ollama is running (ollama serve).";
          }
        } else {
          // Fallback: Direct Ollama call (web-only mode)
          // This is always local, no cloud indicator needed
          const apiUrl =
            import.meta.env.VITE_CHAT_API_URL || 'http://localhost:11434/api/chat';

          // Discover available models from Ollama
          let modelToUse = 'llama3.2:latest';
          try {
            const tagsResponse = await fetch('http://localhost:11434/api/tags');
            if (tagsResponse.ok) {
              const tagsData = await tagsResponse.json();
              const models = tagsData.models?.map((m: { name: string }) => m.name) || [];
              // Prefer llama models, then qwen, then any available
              const preferred = models.find((m: string) => m.startsWith('llama')) ||
                               models.find((m: string) => m.startsWith('qwen')) ||
                               models[0];
              if (preferred) modelToUse = preferred;
            }
          } catch {
            // Use default model
          }

          const messagesForLLM = conversation.messages
            .filter((m) => m.role !== 'tool')
            .map((m) => ({ role: m.role, content: m.content }));

          const response = await fetch(apiUrl, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              model: modelToUse,
              messages: [
                { role: 'system', content: AUI_SYSTEM_PROMPT },
                // Include workspace context as a system message
                ...(workspaceContext ? [{ role: 'system', content: `Current workspace:\n${workspaceContext}` }] : []),
                ...messagesForLLM,
                { role: 'user', content: content.trim() },
              ],
              stream: false,
            }),
            signal: abortControllerRef.current.signal,
          });

          if (!response.ok) throw new Error('Ollama not available');
          const data = await response.json();
          assistantContent = data.message?.content || "I couldn't process that.";
          modelUsed = data.model || modelToUse;
          providerUsed = 'ollama';
          isCloud = false; // Direct Ollama is always local
        }

        // Execute tools FIRST (before displaying message)
        const toolContext: AUIToolContext = {
          activeProject: book.activeProject,
          createProject: book.createProject,
          updateChapter: book.updateChapter,
          createChapter: book.createChapter,
          deleteChapter: book.deleteChapter,
          renderBook: book.renderBook,
          getChapter: book.getChapter,
          addPassage: book.addPassage,
          updatePassage: book.updatePassage,
          getPassages: book.getPassages,
          workspace: workspaceState,
        };

        const { results, hasTools } = await executeAllTools(
          assistantContent,
          toolContext
        );

        // Clean tool syntax from response BEFORE displaying
        const cleanedContent = cleanToolsFromResponse(assistantContent);

        // Only add assistant message if there's content after cleaning
        // (If the entire message was just a tool call, show tool results instead)
        if (cleanedContent.trim()) {
          const assistantMessage: ChatMessage = {
            id: `assistant-${Date.now()}`,
            role: 'assistant',
            content: cleanedContent,
            timestamp: new Date(),
            isCloud,
            model: modelUsed,
            provider: providerUsed,
          };

          setConversation((prev) => ({
            ...prev,
            messages: [...prev.messages, assistantMessage],
          }));
        }

        if (hasTools && results.length > 0) {
          // Add tool results message
          const toolMessage: ChatMessage = {
            id: `tools-${Date.now()}`,
            role: 'tool',
            content: results
              .map((r) =>
                r.success ? `✓ ${r.message}` : `✗ ${r.error}`
              )
              .join('\n'),
            timestamp: new Date(),
            toolResults: results,
          };

          setConversation((prev) => ({
            ...prev,
            messages: [...prev.messages, toolMessage],
          }));

          // Run "show don't tell" animations if enabled
          if (settings.animation.enabled) {
            for (const result of results) {
              if (result.teaching) {
                const sequence = teachingToAnimation(
                  'tool',
                  result.teaching
                );
                // Don't await - run in background
                auiAnimator.animate(sequence).catch(() => {});
              }
            }
          }
        }
      } catch (err) {
        if (err instanceof Error && err.name !== 'AbortError') {
          setError(err.message);

          // Add error message to chat
          const errorMessage: ChatMessage = {
            id: `error-${Date.now()}`,
            role: 'system',
            content: `Connection error: ${err.message}. Try asking about the interface - I have built-in knowledge even without the LLM.`,
            timestamp: new Date(),
          };

          setConversation((prev) => ({
            ...prev,
            messages: [...prev.messages, errorMessage],
          }));
        }
      } finally {
        setIsLoading(false);
        abortControllerRef.current = null;
      }
    },
    [conversation.messages, isLoading, book, bookStudio, workspaceState, settings.animation.enabled]
  );

  // Clear conversation
  const clearConversation = useCallback(() => {
    // Archive current if enabled
    if (settings.archive.archiveChats && conversation.messages.length > 1) {
      archiveConversationInternal(conversation).catch((err) => {
        console.error('[AUI] Failed to archive conversation before clearing:', err);
      });
    }
    setConversation(createNewConversation(settings));
  }, [conversation, settings]);

  // Archive conversation
  const archiveConversation = useCallback(async () => {
    await archiveConversationInternal(conversation);
    setConversation((prev) => ({
      ...prev,
      messages: prev.messages.map((m) => ({ ...m, archived: true })),
    }));
  }, [conversation]);

  // Internal archive function
  async function archiveConversationInternal(conv: AUIConversation) {
    if (conv.messages.length <= 1) return; // Don't archive empty conversations

    try {
      // Format as a conversation for archiving
      const content = conv.messages
        .map((m) => {
          const role = m.role === 'user' ? 'You' : 'AUI';
          return `**${role}**: ${m.content}`;
        })
        .join('\n\n');

      const title =
        conv.title ||
        `AUI Chat: ${conv.messages.find((m) => m.role === 'user')?.content.slice(0, 50) || 'Conversation'}`;

      // Send to archive server
      const archiveServer = await getArchiveServerUrl();
      await fetch(`${archiveServer}/api/aui/archive`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          id: conv.id,
          title,
          content,
          messages: conv.messages,
          tags: conv.tags,
          startedAt: conv.startedAt.toISOString(),
        }),
      });
    } catch (err) {
      console.warn('[AUI] Failed to archive conversation:', err);
    }
  }

  // Toggle chat
  const toggleChat = useCallback(() => {
    setIsChatOpen((prev) => !prev);
  }, []);

  const openChat = useCallback(() => {
    setIsChatOpen(true);
  }, []);

  const closeChat = useCallback(() => {
    setIsChatOpen(false);
  }, []);

  // Update settings
  const updateSettings = useCallback(
    <K extends keyof AUISettings>(
      category: K,
      updates: Partial<AUISettings[K]>
    ) => {
      setSettings((prev) => {
        const updated = {
          ...prev,
          [category]: { ...(prev[category] as object), ...updates },
          updatedAt: new Date().toISOString(),
        };
        saveAUISettings(updated);
        return updated;
      });
    },
    []
  );

  // Stop animation
  const stopAnimation = useCallback(() => {
    auiAnimator.stop();
  }, []);

  // Approve an agent proposal
  const approveProposal = useCallback(async (proposalId: string) => {
    const bridge = bridgeRef.current;
    const result = await bridge.approveProposal(proposalId);
    setPendingProposals(bridge.getPendingProposals());

    // Add result to chat
    if (result) {
      const resultMessage: ChatMessage = {
        id: `approved-${proposalId}`,
        role: 'tool',
        content: result.success
          ? `✓ Proposal approved: ${result.message || 'Action completed'}`
          : `✗ Proposal execution failed: ${result.error}`,
        timestamp: new Date(),
        toolResults: [result],
      };
      setConversation((prev) => ({
        ...prev,
        messages: [...prev.messages, resultMessage],
      }));
    }

    return result;
  }, []);

  // Reject an agent proposal
  const rejectProposal = useCallback((proposalId: string, reason?: string) => {
    const bridge = bridgeRef.current;
    bridge.rejectProposal(proposalId, reason);
    setPendingProposals(bridge.getPendingProposals());

    // Add rejection to chat
    const rejectMessage: ChatMessage = {
      id: `rejected-${proposalId}`,
      role: 'system',
      content: `Proposal rejected${reason ? `: ${reason}` : ''}`,
      timestamp: new Date(),
    };
    setConversation((prev) => ({
      ...prev,
      messages: [...prev.messages, rejectMessage],
    }));
  }, []);

  // Request work from an agent
  const requestAgentWork = useCallback(
    async (
      agentId: string,
      taskType: string,
      payload: unknown,
      projectId?: string
    ) => {
      const bridge = bridgeRef.current;
      return bridge.requestAgentWork(agentId, taskType, payload, projectId);
    },
    []
  );

  // Context value
  const value: AUIContextValue = {
    state: {
      conversation,
      isLoading,
      error,
      animation: animationState,
      settings,
      isChatOpen,
      pendingProposals,
      agents,
      agentBridgeConnected,
    },
    sendMessage,
    clearConversation,
    archiveConversation,
    toggleChat,
    openChat,
    closeChat,
    updateSettings,
    stopAnimation,
    approveProposal,
    rejectProposal,
    requestAgentWork,
    setWorkspace: setWorkspaceState,
  };

  return <AUIContext.Provider value={value}>{children}</AUIContext.Provider>;
}

// ═══════════════════════════════════════════════════════════════════
// HOOKS
// ═══════════════════════════════════════════════════════════════════

/**
 * Hook for just the chat state
 */
export function useAUIChat() {
  const { state, sendMessage, clearConversation, toggleChat, openChat, closeChat } = useAUI();
  return {
    messages: state.conversation.messages,
    isLoading: state.isLoading,
    error: state.error,
    isOpen: state.isChatOpen,
    sendMessage,
    clearConversation,
    toggleChat,
    openChat,
    closeChat,
  };
}

/**
 * Hook for animation state
 */
export function useAUIAnimation() {
  const { state, stopAnimation } = useAUI();
  return {
    ...state.animation,
    stop: stopAnimation,
  };
}

/**
 * Hook for settings
 */
export function useAUISettingsContext() {
  const { state, updateSettings } = useAUI();
  return {
    settings: state.settings,
    update: updateSettings,
  };
}

/**
 * Hook for agent bridge functionality
 */
export function useAUIAgents() {
  const { state, approveProposal, rejectProposal, requestAgentWork } = useAUI();
  return {
    pendingProposals: state.pendingProposals,
    agents: state.agents,
    isConnected: state.agentBridgeConnected,
    approveProposal,
    rejectProposal,
    requestAgentWork,
  };
}
